{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load Dataset\n",
    "def load_dataset(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Handle Missing Values\n",
    "def handle_missing_values(df):\n",
    "    df['person_emp_length'] = df['person_emp_length'].fillna(value=4)\n",
    "    df['loan_int_rate'] = df['loan_int_rate'].fillna(value=10.99)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Filter DataFrame\n",
    "def filter_dataframe(df, min_age, max_age, min_income, max_income, min_loan_amount):\n",
    "    df = df[(df['person_age'] >= min_age) & (df['person_age'] <= max_age) &\n",
    "                     (df['person_income'] >= min_income) & (df['person_income'] <= max_income) &\n",
    "                     (df['loan_amnt'] >= min_loan_amount) & (df['person_home_ownership'] == 'OWN')]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Identifying the target variable\n",
    "def extract_features_and_target(df):\n",
    "    y = df['loan_status']\n",
    "    x = df[['person_age', 'person_income', 'person_home_ownership', 'person_emp_length', 'loan_intent', 'loan_grade',\n",
    "            'loan_amnt', 'loan_int_rate', 'loan_percent_income', 'cb_person_default_on_file', 'cb_person_cred_hist_length']]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Splitting the data into train and test\n",
    "def split_train_test_data(x, y, random_state=4, train_size=0.75):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=random_state, train_size=train_size)\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Preprocess Train Data\n",
    "def preprocess_train_data(x_train):\n",
    "    scaler = StandardScaler()\n",
    "    x_train_num_scaled = scaler.fit_transform(x_train.select_dtypes(include=['int64', 'float64']))\n",
    "    x_train_num_pre = pd.DataFrame(x_train_num_scaled, columns=x_train.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    \n",
    "    x_train_cat = x_train.select_dtypes(include=['object'])\n",
    "    encoder = OneHotEncoder(drop='first')\n",
    "    x_train_cat_encoded = pd.DataFrame(encoder.fit_transform(x_train_cat).toarray(), columns=encoder.get_feature_names_out(x_train_cat.columns))\n",
    "    \n",
    "    # Ensure the columns match before concatenating\n",
    "    if not x_train_num_pre.index.equals(x_train_cat_encoded.index):\n",
    "        x_train_cat_encoded.index = x_train_num_pre.index\n",
    "    \n",
    "    x_train_transformed = pd.concat([x_train_num_pre, x_train_cat_encoded], axis=1)\n",
    "    \n",
    "    return x_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Preprocess Test Data\n",
    "def preprocess_test_data(x_test, scaler, encoder):\n",
    "    x_test_num_scaled = scaler.transform(x_test.select_dtypes(include=['int64', 'float64']))\n",
    "    x_test_num_pre = pd.DataFrame(x_test_num_scaled, columns=x_test.select_dtypes(include=['int64', 'float64']).columns)\n",
    "    \n",
    "    x_test_cat = x_test.select_dtypes(include=['object'])\n",
    "    x_test_cat_encoded = pd.DataFrame(encoder.transform(x_test_cat).toarray(), columns=encoder.get_feature_names_out(x_test_cat.columns))\n",
    "    \n",
    "    # Ensure the columns match before concatenating\n",
    "    if not x_test_num_pre.index.equals(x_test_cat_encoded.index):\n",
    "        x_test_cat_encoded.index = x_test_num_pre.index\n",
    "    \n",
    "    x_test_transformed = pd.concat([x_test_num_pre, x_test_cat_encoded], axis=1)\n",
    "    \n",
    "    return x_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Model Building-knn\n",
    "def build_knn_model(x_train_transformed, y_train):\n",
    "    classifier = KNeighborsClassifier()\n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Model Building - Logistic Regression\n",
    "def build_logistic_regression_model(x_train_transformed, y_train):\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Model Building - Support Vector Machine (SVM)\n",
    "def build_svm_model(x_train_transformed, y_train):\n",
    "    classifier = SVC()\n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Model Building - Decision Tree\n",
    "def build_decision_tree_model(x_train_transformed, y_train):\n",
    "    classifier = DecisionTreeClassifier()\n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Model Building - Random Forest\n",
    "def build_random_forest_model(x_train_transformed, y_train):\n",
    "    classifier = RandomForestClassifier()\n",
    "    classifier.fit(x_train_transformed, y_train)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Model Evaluation\n",
    "def evaluate_model(classifier, x_test_transformed, y_test):\n",
    "    y_test_pred = classifier.predict(x_test_transformed)\n",
    "    accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    confusion = confusion_matrix(y_test, y_test_pred)\n",
    "    return accuracy, confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating knn model:\n",
      "Accuracy: 0.9722222222222222\n",
      "confusion [[140   0]\n",
      " [  4   0]]\n",
      "Evaluating Logistic Regression:\n",
      "Accuracy: 0.9861111111111112\n",
      "confusion [[140   0]\n",
      " [  2   2]]\n",
      "Evaluating SVM:\n",
      "Accuracy: 0.9722222222222222\n",
      "confusion [[140   0]\n",
      " [  4   0]]\n",
      "Evaluating Decision Tree:\n",
      "Accuracy: 0.9722222222222222\n",
      "confusion [[139   1]\n",
      " [  3   1]]\n",
      "Evaluating Random Forest:\n",
      "Accuracy: 0.9791666666666666\n",
      "confusion [[140   0]\n",
      " [  3   1]]\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Main Function\n",
    "def main():\n",
    "    df = load_dataset('/Users/tarunreddy/Downloads/credit_risk_dataset.csv')\n",
    "    df = handle_missing_values(df)\n",
    "    df = filter_dataframe(df, 23, 60, 66074, 6000000, 5000)\n",
    "    x, y = extract_features_and_target(df)\n",
    "    x_train, x_test, y_train, y_test = split_train_test_data(x, y, random_state=4, train_size=0.75)\n",
    "    x_train_transformed = preprocess_train_data(x_train)\n",
    "    \n",
    "    # Fit scaler and encoder on training data only\n",
    "    scaler = StandardScaler()\n",
    "    encoder = OneHotEncoder(drop='first')\n",
    "    x_train_cat = x_train.select_dtypes(include=['object'])\n",
    "    encoder.fit(x_train_cat)\n",
    "    scaler.fit(x_train.select_dtypes(include=['int64', 'float64']))\n",
    "    \n",
    "    x_test_transformed  = preprocess_test_data(x_test, scaler, encoder)\n",
    "    \n",
    "    # Build models\n",
    "    knn_model = build_knn_model(x_train_transformed, y_train)\n",
    "    logistic_regression_model = build_logistic_regression_model(x_train_transformed, y_train)\n",
    "    svm_model = build_svm_model(x_train_transformed, y_train)\n",
    "    decision_tree_model = build_decision_tree_model(x_train_transformed, y_train)\n",
    "    random_forest_model = build_random_forest_model(x_train_transformed, y_train)\n",
    "    \n",
    "    # Evaluate models\n",
    "    models = {\n",
    "        'knn model': knn_model,\n",
    "        'Logistic Regression': logistic_regression_model,\n",
    "        'SVM': svm_model,\n",
    "        'Decision Tree': decision_tree_model,\n",
    "        'Random Forest': random_forest_model\n",
    "    }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Evaluating {model_name}:\")\n",
    "        accuracy,confusion = evaluate_model(model, x_test_transformed, y_test)\n",
    "        print('Accuracy:', accuracy)\n",
    "        print('confusion', confusion)\n",
    "   # Call the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
